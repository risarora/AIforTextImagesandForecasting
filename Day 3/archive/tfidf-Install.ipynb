{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - tensorflow_datasets\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 218kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 251kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/85/c273089eb6efa5644c0a1382ea553554bc0d40e00a46d989ec67f123f8b5/future-0.18.0.tar.gz (830kB)\n",
      "\u001b[K     |████████████████████████████████| 839kB 129kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor (from tensorflow_datasets)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting protobuf>=3.6.1 (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/c2/08685ae86ee1f5a45839e779726640ba981e629da2999ebce17e62639c9a/protobuf-3.10.0-cp36-cp36m-macosx_10_9_intel.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 105kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow_datasets) (1.12.0)\n",
      "Collecting wrapt (from tensorflow_datasets)\n",
      "  Using cached https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting tqdm (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 155kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/ca/5b8c1fe032a458c2c4bcbe509d1401dca9dda35c7fc46b36bb81c2834740/psutil-5.6.3.tar.gz (435kB)\n",
      "\u001b[K     |████████████████████████████████| 440kB 174kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrs (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/e8/2ecaf86b128a34e225807f03b22664302937ab826bd3b7eccab6754d29ea/attrs-19.2.0-py2.py3-none-any.whl (40kB)\n",
      "\u001b[K     |████████████████████████████████| 40kB 206kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow_datasets) (1.16.3)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/81/221d09d90176fd90aed4b530e31b8fedf207385767c06d1d46c550c5e418/promise-2.2.1.tar.gz\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/c2/e4ed82a725c9f8160a0ed73f0511773be9f76343def86f6f47121f0e8430/tensorflow_metadata-0.15.0-py2.py3-none-any.whl\n",
      "Collecting absl-py (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 176kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow_datasets) (2.21.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow_datasets) (39.0.1)\n",
      "Collecting googleapis-common-protos (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.3.9)\n",
      "Building wheels for collected packages: dill, future, termcolor, wrapt, psutil, promise, absl-py, googleapis-common-protos\n",
      "\u001b[33m  WARNING: Building wheel for dill failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/59'\u001b[0m\n",
      "\u001b[33m  WARNING: Building wheel for future failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/2c'\u001b[0m\n",
      "\u001b[33m  WARNING: Building wheel for termcolor failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/7c'\u001b[0m\n",
      "\u001b[33m  WARNING: Building wheel for wrapt failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/d7'\u001b[0m\n",
      "\u001b[33m  WARNING: Building wheel for psutil failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/90'\u001b[0m\n",
      "\u001b[33m  WARNING: Building wheel for promise failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/92/84'\u001b[0m\n",
      "\u001b[33m  WARNING: Building wheel for absl-py failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/a7'\u001b[0m\n",
      "\u001b[33m  WARNING: Building wheel for googleapis-common-protos failed: [Errno 13] Permission denied: '/Users/rarora17/Library/Caches/pip/wheels/9e'\u001b[0m\n",
      "Failed to build dill future termcolor wrapt psutil promise absl-py googleapis-common-protos\n",
      "Installing collected packages: dill, future, termcolor, protobuf, wrapt, tqdm, psutil, attrs, promise, googleapis-common-protos, tensorflow-metadata, absl-py, tensorflow-datasets\n",
      "  Running setup.py install for dill ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Complete output from command /Library/Frameworks/Python.framework/Versions/3.6/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/private/var/folders/_d/v8bks58x3nq841dkb6ggbhgx9qd1fb/T/pip-install-zkgzkrak/dill/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/_d/v8bks58x3nq841dkb6ggbhgx9qd1fb/T/pip-record-4kwo1k5e/install-record.txt --single-version-externally-managed --compile:\u001b[0m\n",
      "\u001b[31m    ERROR: running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib\n",
      "    creating build/lib/dill\n",
      "    copying dill/__diff.py -> build/lib/dill\n",
      "    copying dill/pointers.py -> build/lib/dill\n",
      "    copying dill/__init__.py -> build/lib/dill\n",
      "    copying dill/temp.py -> build/lib/dill\n",
      "    copying dill/settings.py -> build/lib/dill\n",
      "    copying dill/_objects.py -> build/lib/dill\n",
      "    copying dill/_dill.py -> build/lib/dill\n",
      "    copying dill/info.py -> build/lib/dill\n",
      "    copying dill/detect.py -> build/lib/dill\n",
      "    copying dill/source.py -> build/lib/dill\n",
      "    copying dill/objtypes.py -> build/lib/dill\n",
      "    creating build/lib/dill/tests\n",
      "    copying tests/test_functors.py -> build/lib/dill/tests\n",
      "    copying tests/test_restricted.py -> build/lib/dill/tests\n",
      "    copying tests/test_weakref.py -> build/lib/dill/tests\n",
      "    copying tests/test_extendpickle.py -> build/lib/dill/tests\n",
      "    copying tests/test_module.py -> build/lib/dill/tests\n",
      "    copying tests/test_source.py -> build/lib/dill/tests\n",
      "    copying tests/test_detect.py -> build/lib/dill/tests\n",
      "    copying tests/__init__.py -> build/lib/dill/tests\n",
      "    copying tests/test_nested.py -> build/lib/dill/tests\n",
      "    copying tests/test_diff.py -> build/lib/dill/tests\n",
      "    copying tests/test_mixins.py -> build/lib/dill/tests\n",
      "    copying tests/test_temp.py -> build/lib/dill/tests\n",
      "    copying tests/test_selected.py -> build/lib/dill/tests\n",
      "    copying tests/test_file.py -> build/lib/dill/tests\n",
      "    copying tests/test_check.py -> build/lib/dill/tests\n",
      "    copying tests/test_functions.py -> build/lib/dill/tests\n",
      "    copying tests/test_classdef.py -> build/lib/dill/tests\n",
      "    copying tests/test_moduledict.py -> build/lib/dill/tests\n",
      "    copying tests/test_properties.py -> build/lib/dill/tests\n",
      "    copying tests/__main__.py -> build/lib/dill/tests\n",
      "    copying tests/test_objects.py -> build/lib/dill/tests\n",
      "    copying tests/test_recursive.py -> build/lib/dill/tests\n",
      "    running build_scripts\n",
      "    creating build/scripts-3.6\n",
      "    copying and adjusting scripts/undill -> build/scripts-3.6\n",
      "    copying and adjusting scripts/get_objgraph -> build/scripts-3.6\n",
      "    changing mode of build/scripts-3.6/undill from 644 to 755\n",
      "    changing mode of build/scripts-3.6/get_objgraph from 644 to 755\n",
      "    running install_lib\n",
      "    creating /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/dill\n",
      "    error: could not create '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/dill': Permission denied\n",
      "    ----------------------------------------\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Command \"/Library/Frameworks/Python.framework/Versions/3.6/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/private/var/folders/_d/v8bks58x3nq841dkb6ggbhgx9qd1fb/T/pip-install-zkgzkrak/dill/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/_d/v8bks58x3nq841dkb6ggbhgx9qd1fb/T/pip-record-4kwo1k5e/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/_d/v8bks58x3nq841dkb6ggbhgx9qd1fb/T/pip-install-zkgzkrak/dill/\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-49ec01a3019e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the tf.__version__ is 1.x, please run this cell\n",
    "#!pip install tensorflow==2.0.0-beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-53f57c10d3aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
