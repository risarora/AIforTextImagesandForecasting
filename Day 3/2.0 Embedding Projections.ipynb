{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Projector\n",
    "\n",
    "http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./image/imdbdataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -q tensorflow_datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install -c anaconda tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0429 15:52:31.549160 140735952987008 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from ipywidgets import IntProgress\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 15:53:41.718355 140735952987008 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "imdb, info = tfds.load(\"imdb_reviews\",with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = imdb['train'] , imdb['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the sentences to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = []\n",
    "training_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0ab77098386a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtraining_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtraining_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\n",
    "for s,l in train_data:\n",
    "  training_sentences.append(str(s.numpy()))\n",
    "  training_labels.append(l.numpy())\n",
    "  \n",
    "for s,l in test_data:\n",
    "  test_sentences.append(str(s.numpy()))\n",
    "  test_labels.append(l.numpy())\n",
    "  \n",
    "# Convert arrays to numpy arrays\n",
    "training_labels_final = np.array(training_labels)\n",
    "training_sentences_final = np.array(training_sentences)\n",
    "testing_labels_final = np.array(test_labels)\n",
    "testing_sentences_final = np.array(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(training_labels_final.shape)\n",
    "print(training_sentences_final.shape)\n",
    "print(testing_labels_final.shape)\n",
    "print(testing_sentences_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "b\"Any movie that portrays the hard-working responsible husband as the person who has to change because of bored, cheating wife is an obvious result of 8 years of the Clinton era.<br /><br />It's little wonder that this movie was written by a woman.\"\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[2])\n",
    "print(training_sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "b'The orange tone to everything was just yucky. Oh yeah, the main character lives in a ghetto that is all orange-tinted with orange-tinted people. Meanwhile, to mentally escape from this crushing poverty of the body, she plays a full-immersion video game (which sucks in that no rules are clear and no logic follows the gameplay). She apparently earns an income playing the game but she is revealed to not be an employee of the game company?. Lots of non-speaking pauses later the story drags on slowly. She uses a glitchy orange computer interface with an operating interface that is so visually annoying and I can only suspect a Microsoft future release.<br /><br />Meanwhile, I the viewer, ask basically why she is wasting her precious time in some moronic game when she barely has the necessities of life? Oh yeah, playing games is fun, but what is the point when you\\'re almost starving? While she is piddling her life away playing some lousy even-more-orange-tinted lame full-immersion video game her dog runs off (probably looking for an owner who pays at least a moment of attention to it and feeds it regularly) or is stolen from the woman (while she is ignoring her lousy orange-tinted reality).<br /><br />Meanwhile she obsesses over some game her game-playing team lost the entire uninteresting movie. Yawn. So she wants to be the best of the best, go get them Ash Catchem (got to bore us all). Golly, this main character sucks as a human being as well and has no redeeming qualities aside from her physical beauty (which she could barter for some manner to escape her crushing poverty).<br /><br />So she reaches the \"Real\" level and it, at least, not sucks horribly and she is sent to kill a former comatose teammate mentally living in the \"Real\" level. Finally the sucky boring bland orange-tinted movie is no longer a tedious chore to watch, but has the potential to say something along the lines \"the main character is trapped in imaginary computer-generated poverty and she is actually in the real world now\". Perhaps she will do the murder deed and live in the real world now? Well, she kills the guy and he vanishes in a digital effect. Wow! Thanks idiotic director. You suck, you suck so very much, director.<br /><br />Here the director had an iota of a chance to redeem himself slightly by burying this lousy lame moronic cruddy movie with a philosophical twist.<br /><br />The director could have said, \"The REAL WORLD is there and if you live in it and contribute to it to make it better, it won\\'t be some cruddy orange-tinted poverty land.\" A clever way to make this suck-tacular movie a agonizingly slow lesson on basic civic pride (for the 1% of the viewers that haven\\'t found something actually entertaining to watch at this point or are movie-masochists).<br /><br />Nope, director. The director had to screw this all up by tossing in some cruddy digital effect and ruin all chances of redemption for this awfully lousy movie which was a waste of money, a waste of time, and a waste of viewer trust.<br /><br />After that, it ends. Good riddance. I hope the director chokes on it. I\\'m putting this HACK on my \"avoid at all costs\" list for any other films his name is attached to.'\n"
     ]
    }
   ],
   "source": [
    "item=24999\n",
    "print(training_labels_final[item])\n",
    "print(training_sentences[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Create instance of tokenizer\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "\n",
    "# fit the tokenizer on the training set\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "# Create index of words\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Replace the string with their word indexes \n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "\n",
    "# pad or Truncate the sentences based on the max_length value\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "# Testing Set\n",
    "# Tokenize the testing sentences with the tokenizer created from testing sentences\n",
    "testing_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "# pad or Truncate the sentences based on the max_length value\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 120)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OOV> young iranian women dress as boys and try to get into a world cup <OOV> match between iran and <OOV> when they 're caught they 're penned in an area where the match remains within <OOV> but out of sight the prisoners <OOV> to be let go but rules are rules br br given the <OOV> of its director <OOV> panahi it was <OOV> to discover that <OOV> is a comedy and a frequently hilarious one in 1997 's the mirror panahi presents two versions of iranian <OOV> and leaves the audience to wonder which one is real in 2000 's the circle several iranian women step outside the system their <OOV> are different but they all end up\n",
      "b'Several young Iranian women dress as boys and try to get into a World Cup qualifying match between Iran and Bahrain. When they\\'re caught, they\\'re penned in an area where the match remains within earshot, but out of sight. The prisoners plead to be let go, but rules are rules.<br /><br />Given the pedigree of its director, Jafar Panahi, it was disarming to discover that Offside is a comedy, and a frequently hilarious one. In 1997\\'s The Mirror, Panahi presents two versions of Iranian girlhood and leaves the audience to wonder which one is \"real\". In 2000\\'s The Circle, several Iranian women step outside the system; their transgressions are different, but they all end up in the same tragic place.<br /><br />However, thinking now about Offside, it\\'s hard to imagine it as anything other than a comedy, because the situation it presents is so obviously ridiculous. As the women demand to know why they can\\'t watch the soccer match and their captors struggle to answer, the only possible outcome is comedy.<br /><br />What makes Offside most affecting is that the young women are not portrayed as activists attacking the system. They are simply soccer fans and patriots, and despite the fact that they are clearly being treated unfairly, they never lose their focus on the match and the historic victory that is within their nation\\'s grasp.'\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[3]))\n",
    "print(training_sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 5s 185us/sample - loss: 9.2207e-05 - acc: 1.0000 - val_loss: 0.8280 - val_acc: 0.8267\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 5s 185us/sample - loss: 5.7258e-05 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 0.8265\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 5s 187us/sample - loss: 3.6185e-05 - acc: 1.0000 - val_loss: 0.8920 - val_acc: 0.8270\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 5s 188us/sample - loss: 2.2955e-05 - acc: 1.0000 - val_loss: 0.9226 - val_acc: 0.8271\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 5s 188us/sample - loss: 1.4181e-05 - acc: 1.0000 - val_loss: 0.9543 - val_acc: 0.8272\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 5s 192us/sample - loss: 8.9718e-06 - acc: 1.0000 - val_loss: 0.9831 - val_acc: 0.8265\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 5s 201us/sample - loss: 5.7218e-06 - acc: 1.0000 - val_loss: 1.0116 - val_acc: 0.8266\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 5s 214us/sample - loss: 3.6190e-06 - acc: 1.0000 - val_loss: 1.0386 - val_acc: 0.8264\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 6s 228us/sample - loss: 2.3020e-06 - acc: 1.0000 - val_loss: 1.0651 - val_acc: 0.8261\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 6s 241us/sample - loss: 1.4764e-06 - acc: 1.0000 - val_loss: 1.0914 - val_acc: 0.8259\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [9.220737520372495e-05,\n",
       "  5.72577488841489e-05,\n",
       "  3.618520189542323e-05,\n",
       "  2.2955438579665498e-05,\n",
       "  1.4180951579182874e-05,\n",
       "  8.97175200516358e-06,\n",
       "  5.721847122476902e-06,\n",
       "  3.619031097041443e-06,\n",
       "  2.3019605360605054e-06,\n",
       "  1.4763939488329926e-06],\n",
       " 'acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'val_loss': [0.8279541819947958,\n",
       "  0.8599751739788055,\n",
       "  0.8919651262843609,\n",
       "  0.9226111056375503,\n",
       "  0.9542629728603363,\n",
       "  0.9830620627832413,\n",
       "  1.0115778042697907,\n",
       "  1.0385503787845838,\n",
       "  1.0651467025566101,\n",
       "  1.091361799912001],\n",
       " 'val_acc': [0.82668,\n",
       "  0.82648,\n",
       "  0.827,\n",
       "  0.82712,\n",
       "  0.8272,\n",
       "  0.82652,\n",
       "  0.8266,\n",
       "  0.8264,\n",
       "  0.82612,\n",
       "  0.82592]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss=history_dict['loss']\n",
    "val_loss=history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./image/mapthewords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View in embedding Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, vocab_size):\n",
    "  word = reverse_word_index[word_num]\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "  pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11], [], [1430], [968], [4], [1537], [1537], [4739], [], [790], [2015], [11], [2922], [2190], [], [790], [2015], [11], [579], [], [11], [579], [], [4], [1783], [4], [4508], [11], [2922], [1277], [], [], [2015], [1005], [2922], [968], [579], [790], []]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I really think this is amazing. honest.\"\n",
    "sequence = tokenizer.texts_to_sequences(sentence)\n",
    "print(sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
