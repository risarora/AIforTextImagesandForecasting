{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\tLab: Single-Layer Perceptron in TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the input and output vector\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "??model.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0429 14:22:08.430932 140735952987008 deprecation_wrapper.py:119] From /anaconda2/envs/bert/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0429 14:22:08.467402 140735952987008 deprecation_wrapper.py:119] From /anaconda2/envs/bert/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0429 14:22:08.472193 140735952987008 deprecation_wrapper.py:119] From /anaconda2/envs/bert/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0429 14:22:08.501988 140735952987008 deprecation_wrapper.py:119] From /anaconda2/envs/bert/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=2))\n",
    "model.add(Activation('softmax'))\n",
    "sgd = SGD(lr=0.1)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/bert/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "W0428 14:15:44.283635 140735952987008 deprecation_wrapper.py:119] From /anaconda2/envs/bert/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0428 14:15:44.292292 140735952987008 deprecation_wrapper.py:119] From /anaconda2/envs/bert/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.5000\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1063b04e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,  batch_size=1, nb_epoch=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\tLab: First DNN in TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data \n",
    "training_data = np.array([[0,0],\n",
    "                          [0,1],\n",
    "                          [1,0],\n",
    "                          [1,1]], \"float32\")\n",
    "\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[0],[1],[1],[0]], \"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/bert/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 1s - loss: 0.3053 - binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      " - 0s - loss: 0.3049 - binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      " - 0s - loss: 0.3045 - binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      " - 0s - loss: 0.3042 - binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      " - 0s - loss: 0.3038 - binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      " - 0s - loss: 0.3035 - binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.3031 - binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      " - 0s - loss: 0.3027 - binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      " - 0s - loss: 0.3024 - binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.3020 - binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      " - 0s - loss: 0.3017 - binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.3013 - binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      " - 0s - loss: 0.3010 - binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      " - 0s - loss: 0.3006 - binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.3003 - binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.2999 - binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.2996 - binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      " - 0s - loss: 0.2993 - binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.2989 - binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.2986 - binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.2982 - binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.2979 - binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.2975 - binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.2972 - binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.2969 - binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.2965 - binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.2962 - binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.2959 - binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.2955 - binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.2952 - binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.2949 - binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.2946 - binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.2942 - binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      " - 0s - loss: 0.2939 - binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.2936 - binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.2933 - binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.2930 - binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.2926 - binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.2923 - binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      " - 0s - loss: 0.2920 - binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.2917 - binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.2914 - binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      " - 0s - loss: 0.2911 - binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.2908 - binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.2905 - binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      " - 0s - loss: 0.2902 - binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.2899 - binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.2896 - binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.2893 - binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.2890 - binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      " - 0s - loss: 0.2887 - binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.2884 - binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.2881 - binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.2878 - binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      " - 0s - loss: 0.2875 - binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      " - 0s - loss: 0.2872 - binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.2869 - binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.2866 - binary_accuracy: 0.5000\n",
      "Epoch 59/500\n",
      " - 0s - loss: 0.2863 - binary_accuracy: 0.5000\n",
      "Epoch 60/500\n",
      " - 0s - loss: 0.2861 - binary_accuracy: 0.5000\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.2858 - binary_accuracy: 0.5000\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.2855 - binary_accuracy: 0.5000\n",
      "Epoch 63/500\n",
      " - 0s - loss: 0.2852 - binary_accuracy: 0.5000\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.2849 - binary_accuracy: 0.5000\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.2847 - binary_accuracy: 0.5000\n",
      "Epoch 66/500\n",
      " - 0s - loss: 0.2844 - binary_accuracy: 0.5000\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.2841 - binary_accuracy: 0.5000\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.2838 - binary_accuracy: 0.5000\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.2836 - binary_accuracy: 0.5000\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.2833 - binary_accuracy: 0.5000\n",
      "Epoch 71/500\n",
      " - 0s - loss: 0.2830 - binary_accuracy: 0.5000\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.2828 - binary_accuracy: 0.5000\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.2825 - binary_accuracy: 0.5000\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.2823 - binary_accuracy: 0.5000\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.2820 - binary_accuracy: 0.5000\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.2817 - binary_accuracy: 0.5000\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.2815 - binary_accuracy: 0.5000\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.2812 - binary_accuracy: 0.5000\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.2810 - binary_accuracy: 0.5000\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.2807 - binary_accuracy: 0.5000\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.2805 - binary_accuracy: 0.5000\n",
      "Epoch 82/500\n",
      " - 0s - loss: 0.2802 - binary_accuracy: 0.5000\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.2800 - binary_accuracy: 0.5000\n",
      "Epoch 84/500\n",
      " - 0s - loss: 0.2797 - binary_accuracy: 0.5000\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.2795 - binary_accuracy: 0.5000\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.2792 - binary_accuracy: 0.5000\n",
      "Epoch 87/500\n",
      " - 0s - loss: 0.2790 - binary_accuracy: 0.5000\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.2788 - binary_accuracy: 0.5000\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.2785 - binary_accuracy: 0.5000\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.2783 - binary_accuracy: 0.5000\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.2780 - binary_accuracy: 0.5000\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.2778 - binary_accuracy: 0.5000\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.2776 - binary_accuracy: 0.5000\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.2773 - binary_accuracy: 0.5000\n",
      "Epoch 95/500\n",
      " - 0s - loss: 0.2771 - binary_accuracy: 0.5000\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.2769 - binary_accuracy: 0.5000\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.2767 - binary_accuracy: 0.5000\n",
      "Epoch 98/500\n",
      " - 0s - loss: 0.2764 - binary_accuracy: 0.5000\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.2762 - binary_accuracy: 0.5000\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.2760 - binary_accuracy: 0.5000\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.2758 - binary_accuracy: 0.5000\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.2755 - binary_accuracy: 0.5000\n",
      "Epoch 103/500\n",
      " - 0s - loss: 0.2753 - binary_accuracy: 0.5000\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.2751 - binary_accuracy: 0.5000\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.2749 - binary_accuracy: 0.5000\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.2747 - binary_accuracy: 0.5000\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.2745 - binary_accuracy: 0.5000\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.2743 - binary_accuracy: 0.5000\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.2740 - binary_accuracy: 0.5000\n",
      "Epoch 110/500\n",
      " - 0s - loss: 0.2738 - binary_accuracy: 0.5000\n",
      "Epoch 111/500\n",
      " - 0s - loss: 0.2736 - binary_accuracy: 0.5000\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.2734 - binary_accuracy: 0.5000\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.2732 - binary_accuracy: 0.5000\n",
      "Epoch 114/500\n",
      " - 0s - loss: 0.2730 - binary_accuracy: 0.5000\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.2728 - binary_accuracy: 0.5000\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.2726 - binary_accuracy: 0.5000\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.2724 - binary_accuracy: 0.5000\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.2722 - binary_accuracy: 0.5000\n",
      "Epoch 119/500\n",
      " - 0s - loss: 0.2720 - binary_accuracy: 0.5000\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.2718 - binary_accuracy: 0.5000\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.2716 - binary_accuracy: 0.5000\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.2714 - binary_accuracy: 0.5000\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.2712 - binary_accuracy: 0.5000\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.2711 - binary_accuracy: 0.5000\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.2709 - binary_accuracy: 0.5000\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.2707 - binary_accuracy: 0.5000\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.2705 - binary_accuracy: 0.5000\n",
      "Epoch 128/500\n",
      " - 0s - loss: 0.2703 - binary_accuracy: 0.5000\n",
      "Epoch 129/500\n",
      " - 0s - loss: 0.2701 - binary_accuracy: 0.5000\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.2700 - binary_accuracy: 0.5000\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.2698 - binary_accuracy: 0.5000\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.2696 - binary_accuracy: 0.5000\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.2694 - binary_accuracy: 0.5000\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.2692 - binary_accuracy: 0.5000\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.2691 - binary_accuracy: 0.5000\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.2689 - binary_accuracy: 0.5000\n",
      "Epoch 137/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2687 - binary_accuracy: 0.5000\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.2685 - binary_accuracy: 0.5000\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.2684 - binary_accuracy: 0.5000\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.2682 - binary_accuracy: 0.5000\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.2680 - binary_accuracy: 0.5000\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.2679 - binary_accuracy: 0.5000\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.2677 - binary_accuracy: 0.5000\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.2675 - binary_accuracy: 0.5000\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.2674 - binary_accuracy: 0.5000\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.2672 - binary_accuracy: 0.5000\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.2671 - binary_accuracy: 0.5000\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.2669 - binary_accuracy: 0.5000\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.2667 - binary_accuracy: 0.5000\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.2666 - binary_accuracy: 0.5000\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.2664 - binary_accuracy: 0.5000\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.2663 - binary_accuracy: 0.5000\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.2661 - binary_accuracy: 0.5000\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.2660 - binary_accuracy: 0.5000\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.2658 - binary_accuracy: 0.5000\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.2657 - binary_accuracy: 0.5000\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.2655 - binary_accuracy: 0.5000\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.2654 - binary_accuracy: 0.5000\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.2652 - binary_accuracy: 0.5000\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.2651 - binary_accuracy: 0.5000\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.2649 - binary_accuracy: 0.5000\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.2648 - binary_accuracy: 0.5000\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.2647 - binary_accuracy: 0.5000\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.2645 - binary_accuracy: 0.5000\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.2644 - binary_accuracy: 0.5000\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.2642 - binary_accuracy: 0.5000\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.2641 - binary_accuracy: 0.5000\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.2640 - binary_accuracy: 0.5000\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.2638 - binary_accuracy: 0.5000\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.2637 - binary_accuracy: 0.5000\n",
      "Epoch 171/500\n",
      " - 0s - loss: 0.2636 - binary_accuracy: 0.5000\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.2634 - binary_accuracy: 0.5000\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.2633 - binary_accuracy: 0.5000\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.2632 - binary_accuracy: 0.5000\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.2630 - binary_accuracy: 0.5000\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.2629 - binary_accuracy: 0.5000\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.2628 - binary_accuracy: 0.5000\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.2627 - binary_accuracy: 0.5000\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.2625 - binary_accuracy: 0.5000\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.2624 - binary_accuracy: 0.5000\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.2623 - binary_accuracy: 0.5000\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.2622 - binary_accuracy: 0.5000\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.2620 - binary_accuracy: 0.5000\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.2619 - binary_accuracy: 0.5000\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.2618 - binary_accuracy: 0.5000\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.2617 - binary_accuracy: 0.5000\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.2616 - binary_accuracy: 0.5000\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.2615 - binary_accuracy: 0.5000\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.2613 - binary_accuracy: 0.5000\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.2612 - binary_accuracy: 0.5000\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.2611 - binary_accuracy: 0.5000\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.2610 - binary_accuracy: 0.5000\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.2609 - binary_accuracy: 0.5000\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.2608 - binary_accuracy: 0.5000\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.2607 - binary_accuracy: 0.5000\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.2606 - binary_accuracy: 0.5000\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.2605 - binary_accuracy: 0.5000\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.2604 - binary_accuracy: 0.5000\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.2603 - binary_accuracy: 0.5000\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.2601 - binary_accuracy: 0.5000\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.2600 - binary_accuracy: 0.5000\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.2599 - binary_accuracy: 0.5000\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.2598 - binary_accuracy: 0.5000\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.2597 - binary_accuracy: 0.5000\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.2596 - binary_accuracy: 0.5000\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.2595 - binary_accuracy: 0.5000\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.2594 - binary_accuracy: 0.5000\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.2593 - binary_accuracy: 0.5000\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.2593 - binary_accuracy: 0.5000\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.2592 - binary_accuracy: 0.5000\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.2591 - binary_accuracy: 0.5000\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.2590 - binary_accuracy: 0.5000\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.2589 - binary_accuracy: 0.5000\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.2588 - binary_accuracy: 0.5000\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.2587 - binary_accuracy: 0.5000\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.2586 - binary_accuracy: 0.5000\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.2585 - binary_accuracy: 0.5000\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.2584 - binary_accuracy: 0.5000\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.2583 - binary_accuracy: 0.5000\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.2583 - binary_accuracy: 0.5000\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.2582 - binary_accuracy: 0.5000\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.2581 - binary_accuracy: 0.5000\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.2580 - binary_accuracy: 0.5000\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.2579 - binary_accuracy: 0.5000\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.2578 - binary_accuracy: 0.5000\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.2577 - binary_accuracy: 0.5000\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.2577 - binary_accuracy: 0.5000\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.2576 - binary_accuracy: 0.5000\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.2575 - binary_accuracy: 0.5000\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.2574 - binary_accuracy: 0.5000\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.2573 - binary_accuracy: 0.5000\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.2573 - binary_accuracy: 0.5000\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.2572 - binary_accuracy: 0.5000\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.2571 - binary_accuracy: 0.5000\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.2570 - binary_accuracy: 0.5000\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.2570 - binary_accuracy: 0.5000\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.2569 - binary_accuracy: 0.5000\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.2568 - binary_accuracy: 0.5000\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.2567 - binary_accuracy: 0.5000\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.2567 - binary_accuracy: 0.5000\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.2566 - binary_accuracy: 0.5000\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.2565 - binary_accuracy: 0.5000\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.2565 - binary_accuracy: 0.5000\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.2564 - binary_accuracy: 0.5000\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.2563 - binary_accuracy: 0.5000\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.2563 - binary_accuracy: 0.5000\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.2562 - binary_accuracy: 0.5000\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.2561 - binary_accuracy: 0.5000\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.2561 - binary_accuracy: 0.5000\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.2560 - binary_accuracy: 0.5000\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.2559 - binary_accuracy: 0.5000\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.2559 - binary_accuracy: 0.5000\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.2558 - binary_accuracy: 0.5000\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.2557 - binary_accuracy: 0.5000\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.2557 - binary_accuracy: 0.5000\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.2556 - binary_accuracy: 0.5000\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.2556 - binary_accuracy: 0.5000\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.2555 - binary_accuracy: 0.5000\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.2554 - binary_accuracy: 0.5000\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.2554 - binary_accuracy: 0.5000\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.2553 - binary_accuracy: 0.5000\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.2553 - binary_accuracy: 0.5000\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.2552 - binary_accuracy: 0.5000\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.2552 - binary_accuracy: 0.5000\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.2551 - binary_accuracy: 0.5000\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.2551 - binary_accuracy: 0.5000\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.2550 - binary_accuracy: 0.5000\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.2549 - binary_accuracy: 0.5000\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.2549 - binary_accuracy: 0.5000\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.2548 - binary_accuracy: 0.5000\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.2548 - binary_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/500\n",
      " - 0s - loss: 0.2547 - binary_accuracy: 0.5000\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.2547 - binary_accuracy: 0.5000\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.2546 - binary_accuracy: 0.5000\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.2546 - binary_accuracy: 0.5000\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.2545 - binary_accuracy: 0.5000\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.2545 - binary_accuracy: 0.5000\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.2544 - binary_accuracy: 0.5000\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.2544 - binary_accuracy: 0.5000\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.2543 - binary_accuracy: 0.5000\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.2543 - binary_accuracy: 0.5000\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.2543 - binary_accuracy: 0.5000\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.2542 - binary_accuracy: 0.5000\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.2542 - binary_accuracy: 0.5000\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.2541 - binary_accuracy: 0.5000\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.2541 - binary_accuracy: 0.5000\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.2540 - binary_accuracy: 0.5000\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.2540 - binary_accuracy: 0.5000\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.2539 - binary_accuracy: 0.5000\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.2539 - binary_accuracy: 0.5000\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.2539 - binary_accuracy: 0.5000\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.2538 - binary_accuracy: 0.5000\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.2538 - binary_accuracy: 0.5000\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.2537 - binary_accuracy: 0.5000\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.2537 - binary_accuracy: 0.5000\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.2537 - binary_accuracy: 0.5000\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.2536 - binary_accuracy: 0.5000\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.2536 - binary_accuracy: 0.5000\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.2535 - binary_accuracy: 0.5000\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.2535 - binary_accuracy: 0.5000\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.2535 - binary_accuracy: 0.5000\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.2534 - binary_accuracy: 0.5000\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.2534 - binary_accuracy: 0.5000\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.2534 - binary_accuracy: 0.5000\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.2533 - binary_accuracy: 0.5000\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.2533 - binary_accuracy: 0.5000\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.2533 - binary_accuracy: 0.5000\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.2532 - binary_accuracy: 0.5000\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.2532 - binary_accuracy: 0.5000\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.2532 - binary_accuracy: 0.5000\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.2531 - binary_accuracy: 0.5000\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.2531 - binary_accuracy: 0.5000\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.2531 - binary_accuracy: 0.5000\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.2530 - binary_accuracy: 0.5000\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.2530 - binary_accuracy: 0.5000\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.2530 - binary_accuracy: 0.5000\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.2529 - binary_accuracy: 0.5000\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.2529 - binary_accuracy: 0.5000\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.2529 - binary_accuracy: 0.5000\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.2528 - binary_accuracy: 0.5000\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.2528 - binary_accuracy: 0.5000\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.2528 - binary_accuracy: 0.5000\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.2528 - binary_accuracy: 0.5000\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.2527 - binary_accuracy: 0.5000\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.2527 - binary_accuracy: 0.5000\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.2527 - binary_accuracy: 0.5000\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.2527 - binary_accuracy: 0.5000\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.2526 - binary_accuracy: 0.5000\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.2526 - binary_accuracy: 0.5000\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.2526 - binary_accuracy: 0.5000\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.2525 - binary_accuracy: 0.5000\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.2525 - binary_accuracy: 0.5000\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.2525 - binary_accuracy: 0.5000\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.2525 - binary_accuracy: 0.5000\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.2524 - binary_accuracy: 0.5000\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.2524 - binary_accuracy: 0.5000\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.2524 - binary_accuracy: 0.5000\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.2524 - binary_accuracy: 0.5000\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.2524 - binary_accuracy: 0.5000\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.2523 - binary_accuracy: 0.5000\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.2523 - binary_accuracy: 0.5000\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.2523 - binary_accuracy: 0.5000\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.2523 - binary_accuracy: 0.5000\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.2522 - binary_accuracy: 0.7500\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.2522 - binary_accuracy: 0.7500\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.2522 - binary_accuracy: 0.7500\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.2522 - binary_accuracy: 0.7500\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.2522 - binary_accuracy: 0.7500\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.2521 - binary_accuracy: 0.7500\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.2521 - binary_accuracy: 0.7500\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.2521 - binary_accuracy: 0.7500\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.2521 - binary_accuracy: 0.7500\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.2521 - binary_accuracy: 0.7500\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.2520 - binary_accuracy: 0.7500\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.2520 - binary_accuracy: 0.7500\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.2520 - binary_accuracy: 0.7500\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.2520 - binary_accuracy: 0.7500\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.2520 - binary_accuracy: 0.7500\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.2519 - binary_accuracy: 0.7500\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.2519 - binary_accuracy: 0.7500\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.2519 - binary_accuracy: 0.7500\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.2519 - binary_accuracy: 0.7500\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.2519 - binary_accuracy: 0.7500\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.2519 - binary_accuracy: 0.7500\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.2518 - binary_accuracy: 0.7500\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.2518 - binary_accuracy: 0.7500\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.2518 - binary_accuracy: 0.7500\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.2518 - binary_accuracy: 0.7500\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.2518 - binary_accuracy: 0.7500\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.2518 - binary_accuracy: 0.7500\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.2517 - binary_accuracy: 0.7500\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.2517 - binary_accuracy: 0.7500\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.2517 - binary_accuracy: 0.7500\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.2517 - binary_accuracy: 0.7500\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.2517 - binary_accuracy: 0.7500\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.2517 - binary_accuracy: 0.7500\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.2517 - binary_accuracy: 0.7500\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.2516 - binary_accuracy: 0.7500\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.2516 - binary_accuracy: 0.7500\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.2516 - binary_accuracy: 0.7500\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.2516 - binary_accuracy: 0.7500\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.2516 - binary_accuracy: 0.7500\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.2516 - binary_accuracy: 0.7500\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.2516 - binary_accuracy: 0.7500\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.2515 - binary_accuracy: 0.7500\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.2514 - binary_accuracy: 0.7500\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.2513 - binary_accuracy: 0.7500\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.2512 - binary_accuracy: 0.7500\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.2511 - binary_accuracy: 0.7500\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.2510 - binary_accuracy: 0.7500\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.2509 - binary_accuracy: 0.7500\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.2508 - binary_accuracy: 0.7500\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.2507 - binary_accuracy: 0.7500\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.2507 - binary_accuracy: 0.7500\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.2507 - binary_accuracy: 0.5000\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.2507 - binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3af5c2e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, target_data, nb_epoch=500, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4803356 ],\n",
       "       [0.5238917 ],\n",
       "       [0.45654556],\n",
       "       [0.50019187]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 500 Epochs Sigmoid \n",
    "model.predict(training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4976287 ],\n",
       "       [0.49753618],\n",
       "       [0.71253824],\n",
       "       [0.2966142 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 500 Epochs\n",
    "model.predict(training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5280742 ],\n",
       "       [0.4980269 ],\n",
       "       [0.53359985],\n",
       "       [0.42966574]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 50 Epochs\n",
    "model.predict(training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52026874],\n",
       "       [0.46132985],\n",
       "       [0.48004326],\n",
       "       [0.38330978]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 50 Epochs\n",
    "model.predict(training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5083612 ],\n",
       "       [0.427716  ],\n",
       "       [0.43701363],\n",
       "       [0.33743334]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 20 Epochs\n",
    "model.predict(training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(training_data).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the Variables\n",
    "\n",
    "NUM_FEATURES = 2\n",
    "NUM_ITER = 2000\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the input and output variables\n",
    "\n",
    "x = np.array([[0, 0], [1, 0], [1, 1], [0, 1]], np.float32)  # 4x2, input\n",
    "y = np.array([0, 0, 1, 0], np.float32)                      # 4, correct output, AND operation\n",
    "#y = np.array([0, 1, 1, 1], np.float32)                     # OR operation\n",
    "y = np.reshape(y, [4,1])                                    # convert to 4x1\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[4, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[4, 1])\n",
    "\n",
    "W = tf.Variable(tf.zeros([NUM_FEATURES, 1]), tf.float32)\n",
    "B = tf.Variable(tf.zeros([1, 1]), tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yHat = tf.sigmoid( tf.add(tf.matmul(X, W), B) )        # 4x1\n",
    "err = Y - yHat\n",
    "deltaW = tf.matmul(tf.transpose(X), err )    # have to be 2x1\n",
    "deltaB = tf.reduce_sum(err, 0)      # 4, have to 1x1. sum all the biases? yes\n",
    "W_ = W + learning_rate * deltaW\n",
    "B_ = B + learning_rate * deltaB\n",
    "\n",
    "step = tf.group(W.assign(W_), B.assign(B_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for k in range(NUM_ITER):\n",
    "    sess.run([step], feed_dict={X: x, Y: y})\n",
    "\n",
    "W = np.squeeze(sess.run(W))\n",
    "b = np.squeeze(sess.run(B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [2.6895785 2.6895785]\n",
      "b: -4.26431\n",
      "plot_y: [1.7854937  0.38549364]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now plot the fitted line. We need only two points to plot the line\n",
    "plot_x = np.array([np.min(x[:, 0] - 0.2), np.max(x[:, 1]+0.2)])\n",
    "plot_y = - 1 / W[1] * (W[0] * plot_x + b)\n",
    "plot_y = np.reshape(plot_y, [2, -1])\n",
    "plot_y = np.squeeze(plot_y)\n",
    "\n",
    "print('W: ' + str(W))\n",
    "print('b: ' + str(b))\n",
    "print('plot_y: '+ str(plot_y))\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], s=100,c=np.squeeze(y), cmap='viridis')\n",
    "plt.plot(plot_x, plot_y, color='k', linewidth=2)\n",
    "plt.xlim([-0.2, 1.2]); plt.ylim([-0.2, 1.25]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
